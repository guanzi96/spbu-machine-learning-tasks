{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "dhBxdAU-aPhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1B0LD1YXmNf",
        "outputId": "33d70746-1286-4a0b-b54d-5884fc96159c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Codebook for subvector 1:\n",
            "         0         1         2         3         4         5         6    \\\n",
            "0   0.030480 -0.119639 -0.096747  0.025427 -0.094753  0.417124 -0.051446   \n",
            "1  -0.052896 -0.263104  0.189923  0.226979 -0.084419 -0.234670 -0.173113   \n",
            "2  -0.311142 -0.200950  0.023813  0.037042  0.032061 -0.191592  0.063583   \n",
            "3  -0.057471 -0.206931 -0.090752  0.122274 -0.042809  0.027891 -0.264854   \n",
            "4  -0.333751  0.034957  0.013319  0.362404  0.225175  0.049865 -0.308281   \n",
            "5   0.002198 -0.055979  0.081299  0.172955 -0.085070 -0.154067 -0.141806   \n",
            "6  -0.012632  0.117362 -0.108425 -0.141804  0.014180  0.036264 -0.085298   \n",
            "7  -0.056948  0.222933  0.330165 -0.011275  0.000293 -0.018705  0.311166   \n",
            "8   0.149619  0.060697 -0.045302  0.078821 -0.090821 -0.024372 -0.085892   \n",
            "9  -0.019026  0.017143 -0.162784 -0.065920  0.075649 -0.050894  0.083884   \n",
            "10  0.345531 -0.060016  0.362170 -0.196723 -0.208362  0.114162 -0.119513   \n",
            "11  0.067610  0.086755  0.232063  0.149892  0.128611  0.070223 -0.115822   \n",
            "12  0.021585  0.003833 -0.379074 -0.325405  0.173214 -0.243213  0.041688   \n",
            "13  0.038161  0.230421 -0.116388 -0.006997 -0.106883 -0.018427  0.227098   \n",
            "14  0.359328 -0.099084  0.214880 -0.130322 -0.175923  0.070200 -0.039063   \n",
            "15 -0.292436 -0.022453 -0.131226 -0.227978  0.194510  0.063479  0.386365   \n",
            "\n",
            "         7         8         9    ...       182       183       184       185  \\\n",
            "0   0.004035  0.028005  0.125339  ... -0.121337  0.102217  0.245974  0.012261   \n",
            "1   0.145456 -0.128363  0.043636  ... -0.067514  0.155766  0.217961  0.044060   \n",
            "2  -0.041769  0.000825  0.271376  ... -0.098205  0.314832 -0.202574 -0.155260   \n",
            "3   0.001312 -0.019520 -0.086947  ... -0.214556  0.143638 -0.024485  0.025456   \n",
            "4   0.144455 -0.012769  0.074060  ... -0.138775 -0.313260 -0.104087  0.188839   \n",
            "5   0.181060  0.145101  0.050331  ...  0.163632 -0.112096  0.063170 -0.144363   \n",
            "6   0.297839 -0.147018 -0.322919  ...  0.180112 -0.194573  0.022624  0.131382   \n",
            "7   0.128454 -0.034785 -0.229630  ... -0.098752  0.025489 -0.105932  0.007495   \n",
            "8  -0.147800  0.076392  0.055418  ... -0.209944 -0.126911 -0.063771 -0.255103   \n",
            "9  -0.378274  0.284240 -0.042285  ... -0.025747 -0.174262 -0.078814 -0.116187   \n",
            "10 -0.072279 -0.016808  0.067896  ...  0.120332 -0.296322  0.020605  0.083018   \n",
            "11  0.068251 -0.193595  0.270497  ...  0.041006  0.477142  0.039301  0.081877   \n",
            "12  0.014538 -0.195613  0.123204  ...  0.324418  0.228921 -0.231629 -0.003049   \n",
            "13 -0.122607  0.078287  0.030132  ... -0.091801  0.110597 -0.002363  0.190653   \n",
            "14 -0.138564  0.170945 -0.243553  ...  0.025338  0.032283  0.185638  0.005358   \n",
            "15  0.057218 -0.319501 -0.071376  ... -0.013335  0.009407  0.117205  0.077053   \n",
            "\n",
            "         186       187       188       189       190       191  \n",
            "0  -0.070330  0.221750  0.182618 -0.069828  0.098132 -0.002148  \n",
            "1   0.055751 -0.034029 -0.083440  0.229434  0.218640 -0.229237  \n",
            "2   0.055168 -0.089363 -0.030872  0.251656 -0.021985 -0.050844  \n",
            "3  -0.008557  0.252841 -0.254319  0.089099  0.163980 -0.111907  \n",
            "4   0.178999 -0.300350 -0.007330  0.087130 -0.169846 -0.076650  \n",
            "5  -0.168683 -0.084353 -0.042340 -0.099298 -0.281479  0.001296  \n",
            "6   0.196764  0.198553  0.057813 -0.255218 -0.033702 -0.110824  \n",
            "7  -0.059258  0.223394 -0.116365 -0.053133 -0.046096  0.144599  \n",
            "8   0.104457 -0.145165 -0.300875  0.087247 -0.096746  0.381711  \n",
            "9  -0.140692 -0.001905  0.055301 -0.166230 -0.091753 -0.307645  \n",
            "10 -0.132620 -0.021660  0.232227 -0.019250 -0.095572  0.208439  \n",
            "11  0.105889 -0.079531  0.062882 -0.068570 -0.235767 -0.059785  \n",
            "12 -0.182083 -0.152107  0.168563 -0.037504  0.146122  0.109898  \n",
            "13  0.102476 -0.201411  0.078097  0.064214  0.108610  0.043880  \n",
            "14  0.073129  0.057185 -0.257141  0.080107  0.132185  0.131907  \n",
            "15 -0.006380  0.011309  0.038473  0.070028  0.161834  0.046411  \n",
            "\n",
            "[16 rows x 192 columns]\n",
            "Codebook for subvector 2:\n",
            "         0         1         2         3         4         5         6    \\\n",
            "0  -0.138416 -0.254818  0.090176 -0.026302 -0.013575 -0.033937  0.103439   \n",
            "1   0.150024 -0.090520  0.044207 -0.059107 -0.198567 -0.198136 -0.100378   \n",
            "2   0.149568  0.161111  0.131656  0.044115  0.483186 -0.201515 -0.033419   \n",
            "3  -0.069134 -0.181630  0.032509 -0.312021 -0.127800  0.308942  0.232037   \n",
            "4  -0.078166  0.080087  0.346758 -0.081661 -0.041270 -0.107902 -0.052683   \n",
            "5   0.260455 -0.143628 -0.089415  0.286009 -0.112544 -0.020159  0.060857   \n",
            "6  -0.100215  0.362938 -0.587156  0.046612  0.124979  0.022097 -0.288552   \n",
            "7  -0.161866 -0.046493 -0.180502  0.059283 -0.093623 -0.070624 -0.180069   \n",
            "8   0.037289 -0.042157 -0.080887 -0.005435 -0.052601 -0.117802  0.234955   \n",
            "9  -0.042912  0.207086  0.266869  0.213637  0.038190 -0.017191  0.101725   \n",
            "10 -0.052630 -0.122368  0.086614  0.119731  0.129893  0.113784  0.046635   \n",
            "11 -0.050814  0.075216 -0.254877 -0.046119 -0.212984  0.180026 -0.060418   \n",
            "12 -0.048066  0.116265  0.164816 -0.058963 -0.279094 -0.108916 -0.245773   \n",
            "13  0.004521  0.037053  0.115560  0.003738  0.271741  0.139577  0.072031   \n",
            "14 -0.069201 -0.022891 -0.059912 -0.155724 -0.011127 -0.017386  0.011638   \n",
            "15  0.020948 -0.110020 -0.234832 -0.047856  0.002447  0.037721  0.159378   \n",
            "\n",
            "         7         8         9    ...       182       183       184       185  \\\n",
            "0  -0.139530 -0.379257 -0.067920  ...  0.129584 -0.146206 -0.120402  0.150063   \n",
            "1   0.008444 -0.073700  0.037011  ...  0.217459  0.319089  0.266867  0.027613   \n",
            "2   0.256635  0.109782  0.006347  ... -0.302896 -0.044895 -0.178226  0.144118   \n",
            "3   0.079149 -0.086461  0.038792  ... -0.153519  0.166202  0.289157 -0.179117   \n",
            "4  -0.253292 -0.123596  0.190446  ... -0.022672  0.115495 -0.044766  0.201942   \n",
            "5   0.037682  0.096385 -0.160607  ...  0.333658 -0.018870 -0.195593  0.036145   \n",
            "6  -0.207921 -0.206693 -0.131114  ... -0.025863  0.197682  0.011934  0.129727   \n",
            "7  -0.039369  0.133417  0.280640  ... -0.300947 -0.086850  0.010994 -0.100476   \n",
            "8   0.148958  0.366901 -0.102602  ... -0.092177 -0.110554 -0.082028 -0.189656   \n",
            "9  -0.106605 -0.237523  0.060459  ... -0.052910  0.077498 -0.210233 -0.116710   \n",
            "10 -0.082787  0.005845  0.058034  ...  0.061486  0.076032 -0.061031  0.143248   \n",
            "11  0.251584  0.053260  0.235594  ...  0.031825 -0.172893  0.047474 -0.008440   \n",
            "12 -0.027294  0.146907 -0.291378  ...  0.042607 -0.205531 -0.158459  0.072717   \n",
            "13  0.064543  0.157003 -0.119275  ...  0.208883 -0.012317  0.122059 -0.120789   \n",
            "14  0.143483 -0.354684  0.092133  ... -0.198972  0.073881  0.170175  0.032952   \n",
            "15 -0.100253  0.210547  0.031921  ...  0.201478  0.102857  0.285444 -0.281987   \n",
            "\n",
            "         186       187       188       189       190       191  \n",
            "0  -0.072020  0.063419  0.091917 -0.077151  0.096326 -0.017775  \n",
            "1   0.090996  0.162780  0.040554  0.146629 -0.335362 -0.413372  \n",
            "2  -0.266205 -0.036669  0.498671  0.071279 -0.078746 -0.088050  \n",
            "3   0.196488  0.085644  0.005430 -0.185509  0.433262  0.323736  \n",
            "4   0.243757  0.035180 -0.241450  0.055982 -0.006697  0.225499  \n",
            "5   0.076571 -0.043578  0.058726  0.273390  0.030060 -0.008855  \n",
            "6  -0.148215 -0.203835  0.008659  0.055041 -0.038662  0.065876  \n",
            "7  -0.077781 -0.122637 -0.255247  0.104213 -0.083695  0.118624  \n",
            "8   0.109864  0.020497  0.020219  0.210436  0.211131 -0.365452  \n",
            "9   0.078894 -0.117941 -0.154058  0.103139 -0.149777  0.078818  \n",
            "10  0.069949 -0.115921  0.174526 -0.340228 -0.096667  0.039461  \n",
            "11  0.031510 -0.037431  0.070558 -0.040174  0.021574  0.034535  \n",
            "12  0.092717  0.016339 -0.087013 -0.096748 -0.123475  0.150694  \n",
            "13  0.050215  0.002925  0.046814  0.079306  0.295979 -0.049220  \n",
            "14 -0.203222  0.080101 -0.151981 -0.075605  0.178125 -0.282778  \n",
            "15 -0.428752 -0.018088 -0.111995 -0.203076 -0.001418  0.231135  \n",
            "\n",
            "[16 rows x 192 columns]\n",
            "Codebook for subvector 3:\n",
            "         0         1         2         3         4         5         6    \\\n",
            "0  -0.085740  0.230081 -0.161515 -0.273484 -0.006656 -0.223394 -0.120492   \n",
            "1  -0.084250  0.178397  0.094157  0.139714 -0.112546  0.168396  0.042334   \n",
            "2   0.004312 -0.152293 -0.051608 -0.124885 -0.028321 -0.281547 -0.147571   \n",
            "3  -0.166744  0.021523 -0.389656  0.010290 -0.478871  0.214325  0.089779   \n",
            "4  -0.124353  0.046691  0.073199 -0.090370  0.133038  0.056017 -0.092478   \n",
            "5   0.281125 -0.084108 -0.024416  0.014706 -0.001380  0.235613  0.210535   \n",
            "6   0.244430 -0.039723  0.050174 -0.009213  0.106191 -0.450811  0.069919   \n",
            "7   0.015418 -0.095771 -0.007964  0.208119 -0.036219  0.106218  0.154509   \n",
            "8  -0.120194  0.015901  0.043675  0.212652  0.046821 -0.334669 -0.219251   \n",
            "9   0.144249  0.056492  0.236489 -0.313502 -0.107633 -0.128814  0.044432   \n",
            "10  0.149146 -0.077195 -0.162378 -0.104961 -0.031879  0.039871  0.146428   \n",
            "11 -0.008119 -0.050664 -0.057722  0.191378 -0.047216  0.562325  0.165966   \n",
            "12 -0.090053  0.015688 -0.055397  0.074909 -0.187283  0.015976 -0.338322   \n",
            "13 -0.158287  0.122293 -0.089165  0.075290  0.422695  0.208495  0.204604   \n",
            "14 -0.018435 -0.054568  0.302895  0.009631  0.070796 -0.255521 -0.035116   \n",
            "15 -0.056818 -0.163041 -0.089665 -0.137424  0.086070  0.054005 -0.160251   \n",
            "\n",
            "         7         8         9    ...       182       183       184       185  \\\n",
            "0   0.100154 -0.183013 -0.173990  ... -0.025512 -0.131007 -0.308462  0.277249   \n",
            "1   0.089017  0.163106  0.070992  ...  0.198646 -0.216303 -0.304415 -0.240274   \n",
            "2  -0.300957  0.132569 -0.125880  ... -0.021277 -0.136924  0.087482  0.001745   \n",
            "3  -0.253619  0.049725  0.016604  ...  0.034241 -0.097774  0.269105 -0.128454   \n",
            "4  -0.103456 -0.087936  0.003474  ... -0.043356  0.221660 -0.142418  0.028693   \n",
            "5   0.120871  0.006239  0.135272  ...  0.153891 -0.006217 -0.180089 -0.099908   \n",
            "6  -0.036804 -0.127299  0.257905  ...  0.264018 -0.130226 -0.133107 -0.118091   \n",
            "7   0.205654  0.170169 -0.139279  ... -0.164431 -0.005738  0.249297  0.208159   \n",
            "8  -0.034924  0.258039  0.153617  ...  0.063542 -0.173774  0.021841  0.255003   \n",
            "9  -0.101410 -0.008484 -0.268794  ...  0.081116 -0.208294 -0.029979 -0.011190   \n",
            "10  0.047545 -0.008862 -0.037239  ...  0.141890  0.386750 -0.255809 -0.173351   \n",
            "11 -0.252118  0.012713  0.172693  ...  0.054185  0.008931  0.065985 -0.018857   \n",
            "12  0.386921 -0.105615  0.085899  ... -0.216399 -0.063975  0.298298  0.116140   \n",
            "13  0.224364  0.039610 -0.257249  ... -0.106981 -0.180556  0.142910  0.084799   \n",
            "14  0.054272 -0.014090  0.044717  ... -0.171033  0.267878  0.020500 -0.005572   \n",
            "15  0.057193 -0.190446 -0.023087  ... -0.147884  0.294920  0.151512 -0.092056   \n",
            "\n",
            "         186       187       188       189       190       191  \n",
            "0  -0.049643  0.304439 -0.206823  0.171715  0.087807 -0.300264  \n",
            "1  -0.078523 -0.210093 -0.180782 -0.206144  0.137313  0.000115  \n",
            "2  -0.028941  0.142242  0.209337  0.115890  0.086165  0.075349  \n",
            "3  -0.226189 -0.384670  0.138640  0.110364 -0.191840  0.248311  \n",
            "4  -0.331898  0.127449  0.270147  0.308204 -0.072025 -0.168270  \n",
            "5   0.047220 -0.021410  0.124854 -0.364390  0.102514  0.123700  \n",
            "6   0.083899  0.089539 -0.113125  0.223121 -0.041745 -0.075714  \n",
            "7   0.137539  0.099192 -0.140069 -0.014519  0.038933 -0.071866  \n",
            "8   0.028196 -0.169474  0.073010 -0.099397  0.012897  0.331180  \n",
            "9   0.427036  0.105791  0.127519 -0.367669  0.006643  0.182312  \n",
            "10  0.200266 -0.087017  0.240943  0.061690 -0.257982 -0.099749  \n",
            "11  0.062448  0.072363  0.015114 -0.119206 -0.034227 -0.009389  \n",
            "12 -0.271395 -0.229436 -0.031058  0.193528  0.106619 -0.143564  \n",
            "13 -0.261915  0.063643 -0.021396  0.101229  0.380160 -0.386679  \n",
            "14  0.107679  0.038883 -0.173870  0.127624 -0.062584  0.071878  \n",
            "15  0.022089 -0.134779 -0.126745 -0.113455 -0.124585 -0.001528  \n",
            "\n",
            "[16 rows x 192 columns]\n",
            "Codebook for subvector 4:\n",
            "         0         1         2         3         4         5         6    \\\n",
            "0  -0.099641 -0.122917  0.181061 -0.076373 -0.028533  0.174939  0.022198   \n",
            "1   0.076339  0.214198  0.023676 -0.217522 -0.065361  0.034415  0.134235   \n",
            "2   0.203221  0.117173 -0.047428  0.285372  0.313365 -0.224115 -0.098339   \n",
            "3  -0.136449  0.046941  0.071769 -0.221906 -0.032723  0.116584 -0.040292   \n",
            "4   0.023916  0.010547 -0.313905  0.269431 -0.183994  0.012668  0.110618   \n",
            "5   0.060942  0.113446 -0.063552 -0.121730  0.402830 -0.281530 -0.088124   \n",
            "6   0.031555 -0.017699  0.223960 -0.203589 -0.042936  0.192488 -0.086683   \n",
            "7  -0.025452 -0.036347  0.086791  0.049831 -0.337628 -0.052610 -0.252235   \n",
            "8   0.248628  0.238187  0.229921 -0.167466  0.207034 -0.104301 -0.014183   \n",
            "9   0.034343 -0.078813  0.017199  0.099791  0.003584 -0.088325 -0.115985   \n",
            "10 -0.024748 -0.494472 -0.323203 -0.055784 -0.159004  0.171818  0.190559   \n",
            "11 -0.156074  0.160372  0.020896  0.083039 -0.041087  0.010036 -0.100938   \n",
            "12 -0.075177  0.114840 -0.191716 -0.179578  0.098141 -0.042663 -0.072815   \n",
            "13 -0.254069 -0.056208  0.041677  0.090910  0.000086 -0.253529  0.010150   \n",
            "14  0.005079 -0.295489 -0.130071  0.093037 -0.081603  0.077948 -0.010696   \n",
            "15  0.077365  0.030902  0.064650  0.337385  0.182916  0.432175  0.178219   \n",
            "\n",
            "         7         8         9    ...       182       183       184       185  \\\n",
            "0   0.171627  0.103080 -0.213875  ... -0.040716  0.062110 -0.135900 -0.018651   \n",
            "1  -0.180597  0.251506  0.239523  ... -0.076477  0.110277  0.146690 -0.097919   \n",
            "2  -0.058665 -0.317931 -0.154881  ...  0.045669  0.201056  0.030995  0.142468   \n",
            "3   0.140302  0.181794 -0.253174  ...  0.086233  0.186905 -0.235003  0.230097   \n",
            "4  -0.041487  0.197112 -0.090039  ...  0.105728 -0.081990 -0.001033 -0.243454   \n",
            "5  -0.189168 -0.081562  0.040163  ...  0.056946  0.004026  0.276221  0.048537   \n",
            "6   0.017860  0.015461  0.489373  ... -0.081816 -0.119399  0.181315  0.007619   \n",
            "7  -0.116666 -0.188999 -0.213950  ...  0.266665  0.140785  0.067117  0.166974   \n",
            "8  -0.048216  0.161422  0.100790  ... -0.029871 -0.045490 -0.041812 -0.056779   \n",
            "9   0.141163  0.064495  0.022859  ... -0.190329  0.012418 -0.255133  0.076394   \n",
            "10 -0.075835 -0.061138  0.064011  ... -0.005094  0.023856 -0.004436  0.124527   \n",
            "11  0.128047  0.106387 -0.049473  ...  0.100711 -0.269794  0.265187  0.048632   \n",
            "12  0.018514  0.126127 -0.077621  ...  0.021599 -0.228544 -0.181337 -0.221892   \n",
            "13  0.073616 -0.026472  0.260565  ... -0.377556  0.071099 -0.043785 -0.070283   \n",
            "14  0.053181 -0.138954  0.145188  ... -0.011524  0.108957 -0.344511 -0.145841   \n",
            "15 -0.077666 -0.092158 -0.087699  ... -0.028832 -0.086189  0.130605 -0.109811   \n",
            "\n",
            "         186       187       188       189       190       191  \n",
            "0  -0.428455 -0.289607  0.014988  0.021958 -0.264401  0.264413  \n",
            "1   0.102453  0.040510  0.139716 -0.183298  0.350145  0.013857  \n",
            "2   0.264968 -0.191790  0.084078  0.059936 -0.131535  0.013832  \n",
            "3   0.068723 -0.210662 -0.302875  0.103788 -0.240200  0.093755  \n",
            "4   0.011515 -0.039792  0.030131 -0.130828 -0.333271  0.099146  \n",
            "5  -0.338040  0.211412 -0.022811  0.057185 -0.120859  0.017179  \n",
            "6  -0.036537 -0.074056  0.315119 -0.021153  0.438535  0.237628  \n",
            "7   0.009012 -0.162609 -0.091915  0.138149  0.061626  0.318875  \n",
            "8  -0.032946  0.146441  0.151670 -0.093224 -0.091200 -0.072730  \n",
            "9   0.162763 -0.131112  0.035103 -0.295164  0.050139 -0.076782  \n",
            "10 -0.100547  0.230577 -0.300948  0.066252 -0.066920  0.014008  \n",
            "11  0.067616  0.037423 -0.276044  0.126572 -0.040135 -0.063953  \n",
            "12  0.263691 -0.057417  0.043722  0.088702  0.206433 -0.332983  \n",
            "13 -0.044337  0.291657  0.218332 -0.152642 -0.067988 -0.057287  \n",
            "14 -0.055279 -0.174196 -0.249343  0.164934  0.203808 -0.267966  \n",
            "15 -0.014390  0.212252  0.021050  0.035552  0.057737  0.206368  \n",
            "\n",
            "[16 rows x 192 columns]\n",
            "Mean Absolute Error: 27.358581513656276\n",
            "Mean Relative Error: 0.9874896643348424\n"
          ]
        }
      ],
      "source": [
        "class ProductQuantization:\n",
        "    def __init__(self, num_sub, num_clu):\n",
        "        \"\"\"\n",
        "        Initialize the PQ class.\n",
        "\n",
        "        Parameters:\n",
        "        K (int): Number of subvectors.\n",
        "        L (int): Number of clusters for each subvector space.\n",
        "        \"\"\"\n",
        "        self.num_subvectors = num_sub\n",
        "        self.num_clusters = num_clu\n",
        "        self.codebooks = []\n",
        "\n",
        "\n",
        "    def cut(self, data):\n",
        "        \"\"\"\n",
        "        Split vectors into multiple subvectors.\n",
        "\n",
        "        Parameters:\n",
        "        data (List): Input vector data.\n",
        "\n",
        "        Returns:\n",
        "         Subvector arrays after splitting.\n",
        "        \"\"\"\n",
        "        all_data = np.array([np.array_split(vec, self.num_subvectors) for vec in data])\n",
        "        return all_data\n",
        "\n",
        "\n",
        "    def kmeans(self, data):\n",
        "        \"\"\"\n",
        "        Perform KMeans clustering for each subvector space and construct the codebook.\n",
        "\n",
        "        Parameters:\n",
        "        data : Input vector data.\n",
        "        \"\"\"\n",
        "        all_data = self.cut(data)  # Calculate the mean error for the entire data set\n",
        "        for i in range(self.num_subvectors):\n",
        "            sub_vectors = np.vstack([vec[i] for vec in all_data])  # Extraction of a subvector from the i-th subspace\n",
        "            kmeans = KMeans(n_clusters=self.num_clusters, random_state=42).fit(sub_vectors)\n",
        "            self.codebooks.append(kmeans.cluster_centers_)\n",
        "\n",
        "\n",
        "    def quantize(self, vector):\n",
        "        \"\"\"\n",
        "        Quantize the original vector into indices of the codebook.\n",
        "\n",
        "        Parameters:\n",
        "        vector : The input vector.\n",
        "\n",
        "        Returns:\n",
        "        List: Quantized indices.\n",
        "        \"\"\"\n",
        "        subvector_size = len(vector) // self.num_subvectors\n",
        "        quantized_indices = []\n",
        "        for i in range(self.num_subvectors):\n",
        "            subvector = vector[i*subvector_size:(i+1)*subvector_size]\n",
        "            codebook = self.codebooks[i]\n",
        "            distances = np.linalg.norm(codebook - subvector, axis=1)\n",
        "            quantized_indices.append(np.argmin(distances))\n",
        "        return quantized_indices\n",
        "\n",
        "\n",
        "    def reconstruct(self, quantized_indices):\n",
        "        \"\"\"\n",
        "        Reconstruct the vector based on the quantized indices.\n",
        "\n",
        "        Parameters:\n",
        "        quantized_indices (List): The list of quantized indices.\n",
        "\n",
        "        Returns:\n",
        "        The reconstructed vector.\n",
        "        \"\"\"\n",
        "        reconstructed_vector = []\n",
        "        for i, idx in enumerate(quantized_indices):\n",
        "            reconstructed_vector.append(self.codebooks[i][idx])\n",
        "        return np.concatenate(reconstructed_vector)\n",
        "\n",
        "\n",
        "    def compute_error(self, original_vector, reconstructed_vector):\n",
        "        \"\"\"\n",
        "        Compute the absolute and relative error between original and reconstructed vector.\n",
        "\n",
        "        Parameters:\n",
        "        original_vector : The original vector.\n",
        "        reconstructed_vector : The reconstructed vector.\n",
        "\n",
        "        Returns:\n",
        "        Tuple: Absolute error, relative error.\n",
        "        \"\"\"\n",
        "        absolute_error = np.linalg.norm(original_vector - reconstructed_vector)\n",
        "        relative_error = absolute_error / np.linalg.norm(original_vector)\n",
        "        return absolute_error, relative_error\n",
        "\n",
        "\n",
        "    def evaluate_dataset(self, data):\n",
        "        \"\"\"\n",
        "        Evaluate the average error across the dataset.\n",
        "\n",
        "        Parameters:\n",
        "        data (List): Input dataset.\n",
        "\n",
        "        Returns:\n",
        "        Tuple: Mean absolute error, mean relative error.\n",
        "        \"\"\"\n",
        "        absolute_errors = []\n",
        "        relative_errors = []\n",
        "        for vector in data:\n",
        "            quantized_indices = self.quantize(vector)\n",
        "            reconstructed_vector = self.reconstruct(quantized_indices)\n",
        "            abs_err, rel_err = self.compute_error(vector, reconstructed_vector)\n",
        "            absolute_errors.append(abs_err)\n",
        "            relative_errors.append(rel_err)\n",
        "        return np.mean(absolute_errors), np.mean(relative_errors)\n",
        "\n",
        "\n",
        "    def print_codebooks(self):\n",
        "        \"\"\"\n",
        "        Display the codebooks for each subvector.\n",
        "        \"\"\"\n",
        "        for i, codebook in enumerate(self.codebooks):\n",
        "            df = pd.DataFrame(codebook)\n",
        "            print(f\"Codebook for subvector {i+1}:\")\n",
        "            print(df)\n",
        "\n",
        "# Generate data\n",
        "data = np.random.normal(loc = 0, scale = 1, size = (10000, 768))\n",
        "\n",
        "# num_sub = 4 denotes 4 subspaces and num_clu = 16 denotes 16 classes clustered in each subspace\n",
        "pq = ProductQuantization(num_sub = 4, num_clu = 16)\n",
        "pq.kmeans(data)\n",
        "\n",
        "# Quantification of tests and reconstruction of multiple vectors\n",
        "original_vector = data[0]\n",
        "quantized_indices = pq.quantize(original_vector)\n",
        "reconstructed_vector = pq.reconstruct(quantized_indices)\n",
        "\n",
        "# Codebook output as a DataFrame for manual verification\n",
        "pq.print_codebooks()\n",
        "\n",
        "# Calculate the mean error for the entire dataset\n",
        "mean_absolute_error, mean_relative_error = pq.evaluate_dataset(data)\n",
        "print(f\"Mean Absolute Error: {mean_absolute_error}\")\n",
        "print(f\"Mean Relative Error: {mean_relative_error}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The value of mean absolute error has a value of 27.35, which is large, implying that the difference between the original and reconstructed vectors is more significant\n",
        "The average relative error, the result shows that the relative error is close to 1, indicating that the reconstructed vector is very close to the original vector.\n",
        "It is possible that due to the uniformity of normally distributed data, the model has difficulty in finding effective cluster centres through KMeans clustering, which leads to higher reconstruction errors."
      ],
      "metadata": {
        "id": "V0JqdTDsaGjB"
      }
    }
  ]
}